{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {},
      "source": [
        "import azureml.core\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "from azureml.core import Workspace, Experiment, Dataset\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from datetime import datetime"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "This notebook was created using version 1.10.0 of the Azure ML SDK\nYou are currently using version 1.6.0 of the Azure ML SDK"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "print(\"This notebook was created using version 1.10.0 of the Azure ML SDK\")\n",
        "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {},
      "source": [
        "subscription_id='f8292d2d-2fe0-426b-ac4b-39dcf0166725'         # ensure it matches your Azure subscription id\n",
        "resource_group='synapse-rg'      # ensure it matches your resource group name\n",
        "workspace_name='amlworkspace'       # ensure it matches your Azure Machine Learning workspace name\n",
        "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
        "ws.write_config()\n",
        "ws = Workspace.from_config()\n",
        "experiment = Experiment(ws, \"Product_valueIndex\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Subscription ID   f8292d2d-2fe0-426b-ac4b-39dcf0166725\nWorkspace         amlworkspace                        \nSKU               Enterprise                          \nResource Group    synapse-rg                          \nLocation          eastus                              \nRun History Name  automl-bikeshareforecasting"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for the run history container in the workspace\n",
        "experiment_name = 'automl-bikeshareforecasting'\n",
        "\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "output = {}\n",
        "output['Subscription ID'] = ws.subscription_id\n",
        "output['Workspace'] = ws.name\n",
        "output['SKU'] = ws.sku\n",
        "output['Resource Group'] = ws.resource_group\n",
        "output['Location'] = ws.location\n",
        "output['Run History Name'] = experiment_name\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "outputDf = pd.DataFrame(data = output, index = [''])\n",
        "outputDf.T"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "{\n  \"name\": \"workspaceblobstore\",\n  \"container_name\": \"azureml-blobstore-d69578ca-aa37-4ba3-92aa-c5aca34bdeb9\",\n  \"account_name\": \"amlworkspace3032050954\",\n  \"protocol\": \"https\",\n  \"endpoint\": \"core.windows.net\"\n}"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "datastore = ws.get_default_datastore()\n",
        "print(datastore)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "Found existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Choose a name for your cluster.\n",
        "amlcompute_cluster_name = \"bike-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws, name=amlcompute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, amlcompute_cluster_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 10,
          "data": null,
          "ename": "UserErrorException",
          "evalue": "UserErrorException:\n\tMessage: './bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"'./bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\"\n    }\n}",
          "traceback": [
            "UserErrorException : UserErrorException:\n\tMessage: './bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"'./bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\"\n    }\n}",
            "Traceback (most recent call last):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/data/azure_storage_datastore.py\", line 772, in upload_files\n    self._get_upload_from_files(files, target_path, relative_root, False),\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/site-packages/azureml/data/azure_storage_datastore.py\", line 271, in _get_upload_from_files\n    raise UserErrorException(err_msg.format(file_path))\n",
            "azureml.exceptions._azureml_exception.UserErrorException: UserErrorException:\n\tMessage: './bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"'./bike-no.csv' does not point to a file. Please upload the file to cloud first if running in a cloud notebook.\"\n    }\n}\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "datastore = ws.get_default_datastore()\n",
        "datastore.upload_files(files = ['./bike-no.csv'], target_path = 'dataset/', overwrite = True,show_progress = True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {},
      "source": [
        "target_column_name = 'cnt'\n",
        "time_column_name = 'date'\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "instant       date  season  yr  ...   windspeed  casual  registered   cnt\n0  1       2011-01-01  1       0   ...   0.160446   331     654         985 \n1  2       2011-01-02  1       0   ...   0.248539   131     670         801 \n2  3       2011-01-03  1       0   ...   0.248309   120     1229        1349\n3  4       2011-01-04  1       0   ...   0.160296   108     1454        1562\n4  5       2011-01-05  1       0   ...   0.186900   82      1518        1600\n\n[5 rows x 14 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, './bike-no.csv')]).with_timestamp_columns(fine_grain_timestamp=time_column_name) \n",
        "dataset.take(5).to_pandas_dataframe().reset_index(drop=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "instant       date  season  yr  ...   windspeed  casual  registered   cnt\n0  605     2012-08-27  3       1   ...   0.128733   989     5928        6917\n1  606     2012-08-28  3       1   ...   0.190925   935     6105        7040\n2  607     2012-08-29  3       1   ...   0.112562   1177    6520        7697\n3  608     2012-08-30  3       1   ...   0.077117   1172    6541        7713\n4  609     2012-08-31  3       1   ...   0.168533   1433    5917        7350\n\n[5 rows x 14 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# select data that occurs before a specified date\n",
        "train = dataset.time_before(datetime(2012, 8, 31), include_boundary=True)\n",
        "train.to_pandas_dataframe().tail(5).reset_index(drop=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {},
      "source": [],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "instant       date  season  yr  ...   windspeed  casual  registered   cnt\n0  610     2012-09-01  3       1   ...   0.113187   2352    3788        6140\n1  611     2012-09-02  3       1   ...   0.064071   2613    3197        5810\n2  612     2012-09-03  3       1   ...   0.151121   1965    4069        6034\n3  613     2012-09-04  3       1   ...   0.236321   867     5997        6864\n4  614     2012-09-05  3       1   ...   0.187808   832     6280        7112\n\n[5 rows x 14 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "test = dataset.time_after(datetime(2012, 9, 1), include_boundary=True)\n",
        "test.to_pandas_dataframe().head(5).reset_index(drop=True)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {},
      "source": [
        "max_horizon = 14"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {},
      "source": [
        "time_series_settings = {\n",
        "    'time_column_name': time_column_name,\n",
        "    'max_horizon': max_horizon,    \n",
        "    'country_or_region': 'US', # set country_or_region will trigger holiday featurizer\n",
        "    'target_lags': 'auto', # use heuristic based lag setting    \n",
        "    'drop_column_names': ['casual', 'registered'] # these columns are a breakdown of the total and therefore a leak\n",
        "}\n",
        "\n",
        "automl_config = AutoMLConfig(task='forecasting',                             \n",
        "                             primary_metric='normalized_root_mean_squared_error',\n",
        "                             blocked_models = ['ExtremeRandomTrees'],                             \n",
        "                             experiment_timeout_hours=0.3,\n",
        "                             training_data=train,\n",
        "                             label_column_name=target_column_name,\n",
        "                             compute_target=compute_target,\n",
        "                             enable_early_stopping=True,\n",
        "                             n_cross_validations=3, \n",
        "                             max_concurrent_iterations=4,\n",
        "                             max_cores_per_iteration=-1,\n",
        "                             verbosity=logging.INFO,\n",
        "                            **time_series_settings)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "Running on remote or ADB.\nRunning on remote compute: bike-cluster\nParent Run ID: AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8\n\n\rCurrent status: DatasetFeaturizationCompleted. Completed featurizing the CV split.\n\rCurrent status: ModelSelection. Beginning model selection.\nHeuristic parameters: Target_Lag = '[1]'.\n\n\n****************************************************************************************************\nDATA GUARDRAILS: \n\nTYPE:         Frequency detection\nSTATUS:       PASSED\nDESCRIPTION:  The time series was analyzed, all data points are aligned with detected frequency.\n              \n\nTYPE:         Missing feature values imputation\nSTATUS:       PASSED\nDESCRIPTION:  No feature missing values were detected in the training data.\n              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n\nTYPE:         Memory Issues Detection\nSTATUS:       PASSED\nDESCRIPTION:  The selected horizon and lag values were analyzed, and no potential memory issues were detected.\n              Learn more about time-series forecasting configurations: https://aka.ms/AutomatedMLForecastingConfiguration\n\n****************************************************************************************************\n\n****************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n****************************************************************************************************\n\n ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n         0   MaxAbsScaler DecisionTree                      0:00:48       0.0970    0.0970\n         2   RobustScaler ElasticNet                        0:01:53       0.1062    0.0970\n         1   RobustScaler ElasticNet                        0:02:47       0.0940    0.0940\n         3   RobustScaler ElasticNet                        0:03:57       0.0909    0.0909\n         7   StandardScalerWrapper DecisionTree             0:00:44       0.0946    0.0909\n         8   RobustScaler DecisionTree                      0:00:49       0.1369    0.0909\n         9   StandardScalerWrapper DecisionTree             0:00:44       0.1015    0.0909\n         6   StandardScalerWrapper ElasticNet               0:04:23       0.1076    0.0909\n         5   MinMaxScaler DecisionTree                      0:05:11       0.0964    0.0909\n         4   RobustScaler ElasticNet                        0:06:13       0.0942    0.0909\n        10   MaxAbsScaler SGD                               0:00:54       0.0944    0.0909\n        13   MinMaxScaler SGD                               0:00:43       0.1057    0.0909\n        12   MinMaxScaler DecisionTree                      0:00:41       0.1136    0.0909\n        11   StandardScalerWrapper DecisionTree             0:00:45       0.1144    0.0909\n        14   RobustScaler DecisionTree                      0:00:37       0.0878    0.0878\n        17   StandardScalerWrapper SGD                      0:00:39       0.8506    0.0878\n        15   MinMaxScaler DecisionTree                      0:00:54       0.1339    0.0878\n        16   StandardScalerWrapper DecisionTree             0:00:45       0.1243    0.0878\n        18   RobustScaler ElasticNet                        0:00:47       0.0968    0.0878\n        19   MinMaxScaler DecisionTree                      0:00:42       0.1052    0.0878\n        21   MaxAbsScaler DecisionTree                      0:00:41       0.1404    0.0878\n        20   MinMaxScaler DecisionTree                      0:01:00       0.1402    0.0878\n        22   MaxAbsScaler ElasticNet                        0:00:52       0.0937    0.0878\n        23   MinMaxScaler ExtremeRandomTrees                0:00:53       0.1014    0.0878\n        24   RobustScaler DecisionTree                      0:00:39       0.1117    0.0878\n        25   StandardScalerWrapper RandomForest             0:00:47       0.1172    0.0878\n        26   RobustScaler RandomForest                      0:00:53       0.1046    0.0878\n        27   StandardScalerWrapper ExtremeRandomTrees       0:00:52       0.0992    0.0878\n        28   MinMaxScaler ExtremeRandomTrees                0:00:54       0.1100    0.0878\n        30   RobustScaler DecisionTree                      0:00:37       0.1064    0.0878\n        29   StandardScalerWrapper RandomForest             0:00:50       0.0899    0.0878\n        31   RobustScaler ExtremeRandomTrees                0:00:50       0.1075    0.0878\n        32   StandardScalerWrapper ExtremeRandomTrees       0:00:42       0.1115    0.0878\n        35                                                  0:00:21          nan    0.0878\n        34   RobustScaler ExtremeRandomTrees                0:00:49          nan    0.0878\n        33   StandardScalerWrapper RandomForest             0:00:42       0.1046    0.0878\n        37    StackEnsemble                                 0:02:12       0.0614    0.0614\n        36    VotingEnsemble                                0:02:12       0.0806    0.0614\nRun(Experiment: automl-bikeshareforecasting,\nId: AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8,\nType: automl,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "remote_run = experiment.submit(automl_config, show_output=True)\n",
        "remote_run"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "{'runId': 'AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8', 'target': 'bike-cluster', 'status': 'Completed', 'startTimeUtc': '2020-08-01T02:35:53.570736Z', 'endTimeUtc': '2020-08-01T02:51:55.456762Z', 'properties': {'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'primary_metric': 'normalized_root_mean_squared_error', 'train_split': '0', 'acquisition_parameter': '0', 'num_cross_validation': '3', 'target': 'bike-cluster', 'RawAMLSettingsString': \"{'name': 'automl-bikeshareforecasting', 'path': None, 'subscription_id': 'f8292d2d-2fe0-426b-ac4b-39dcf0166725', 'resource_group': 'synapse-rg', 'workspace_name': 'amlworkspace', 'region': 'eastus', 'compute_target': 'bike-cluster', 'spark_service': None, 'azure_service': 'Microsoft.ProjectArcadia', '_local_managed_run_id': None, 'iterations': 1000, 'primary_metric': 'normalized_root_mean_squared_error', 'task_type': 'regression', 'data_script': None, 'validation_size': 0.0, 'n_cross_validations': 3, 'y_min': None, 'y_max': None, 'num_classes': None, 'featurization': 'auto', '_ignore_package_version_incompatibilities': False, 'lag_length': 0, 'is_timeseries': True, 'max_cores_per_iteration': -1, 'max_concurrent_iterations': 4, 'iteration_timeout_minutes': None, 'mem_in_mb': None, 'enforce_time_on_windows': False, 'experiment_timeout_minutes': 18, 'experiment_exit_score': None, 'whitelist_models': None, 'blacklist_algos': None, 'supported_models': ['TensorFlowDNN', 'SGD', 'RandomForest', 'OnlineGradientDescentRegressor', 'KNN', 'GradientBoosting', 'LassoLars', 'DecisionTree', 'XGBoostRegressor', 'FastLinearRegressor', 'TensorFlowLinearRegressor', 'Prophet', 'ExtremeRandomTrees', 'TCNForecaster', 'ElasticNet', 'AutoArima', 'LightGBM'], 'auto_blacklist': True, 'blacklist_samples_reached': False, 'exclude_nan_labels': True, 'verbosity': 20, 'debug_log': 'azureml_automl.log', 'show_warnings': False, 'model_explainability': True, 'service_url': None, 'sdk_url': None, 'sdk_packages': None, 'enable_onnx_compatible_models': False, 'enable_split_onnx_featurizer_estimator_models': False, 'vm_type': 'STANDARD_D2_V2', 'telemetry_verbosity': 20, 'send_telemetry': True, 'enable_dnn': False, 'force_text_dnn': False, 'enable_feature_sweeping': False, 'time_column_name': 'date', 'grain_column_names': None, 'drop_column_names': ['casual', 'registered'], 'max_horizon': 14, 'dropna': False, 'overwrite_columns': True, 'transform_dictionary': {'min': '_automl_target_col', 'max': '_automl_target_col', 'mean': '_automl_target_col'}, 'window_size': None, 'country_or_region': 'US', 'lags': {'_automl_target_col': ['auto']}, 'feature_lags': None, 'seasonality': -1, 'use_stl': None, 'short_series_handling': True, 'enable_early_stopping': True, 'early_stopping_n_iters': 10, 'metrics': None, 'enable_ensembling': True, 'enable_stack_ensembling': True, 'ensemble_iterations': 15, 'enable_tf': False, 'enable_cache': True, 'enable_subsampling': False, 'subsample_seed': None, 'enable_nimbusml': False, 'enable_streaming': False, 'force_streaming': False, 'track_child_runs': True, 'label_column_name': 'cnt', 'weight_column_name': None, 'cv_split_column_names': None, 'cost_mode': 1, 'metric_operation': 'minimize', 'preprocess': True, 'blocked_models': ['ExtremeRandomTrees'], 'scenario': 'SDK-Compatible'}\", 'AMLSettingsJsonString': '{\"name\":\"automl-bikeshareforecasting\",\"path\":null,\"subscription_id\":\"f8292d2d-2fe0-426b-ac4b-39dcf0166725\",\"resource_group\":\"synapse-rg\",\"workspace_name\":\"amlworkspace\",\"region\":\"eastus\",\"compute_target\":\"bike-cluster\",\"spark_service\":null,\"azure_service\":\"Microsoft.ProjectArcadia\",\"_local_managed_run_id\":null,\"iterations\":1000,\"primary_metric\":\"normalized_root_mean_squared_error\",\"task_type\":\"regression\",\"data_script\":null,\"validation_size\":0.0,\"n_cross_validations\":3,\"y_min\":null,\"y_max\":null,\"num_classes\":null,\"featurization\":\"auto\",\"_ignore_package_version_incompatibilities\":false,\"lag_length\":0,\"is_timeseries\":true,\"max_cores_per_iteration\":-1,\"max_concurrent_iterations\":4,\"iteration_timeout_minutes\":null,\"mem_in_mb\":null,\"enforce_time_on_windows\":false,\"experiment_timeout_minutes\":18,\"experiment_exit_score\":null,\"whitelist_models\":null,\"blacklist_algos\":[\"TensorFlowDNN\",\"TensorFlowLinearRegressor\",\"AutoArima\",\"Prophet\"],\"supported_models\":[\"TensorFlowDNN\",\"SGD\",\"RandomForest\",\"OnlineGradientDescentRegressor\",\"KNN\",\"GradientBoosting\",\"LassoLars\",\"DecisionTree\",\"XGBoostRegressor\",\"FastLinearRegressor\",\"TensorFlowLinearRegressor\",\"Prophet\",\"ExtremeRandomTrees\",\"TCNForecaster\",\"ElasticNet\",\"AutoArima\",\"LightGBM\"],\"auto_blacklist\":true,\"blacklist_samples_reached\":false,\"exclude_nan_labels\":true,\"verbosity\":20,\"debug_log\":\"azureml_automl.log\",\"show_warnings\":false,\"model_explainability\":true,\"service_url\":null,\"sdk_url\":null,\"sdk_packages\":null,\"enable_onnx_compatible_models\":false,\"enable_split_onnx_featurizer_estimator_models\":false,\"vm_type\":\"STANDARD_D2_V2\",\"telemetry_verbosity\":20,\"send_telemetry\":true,\"enable_dnn\":false,\"force_text_dnn\":false,\"enable_feature_sweeping\":false,\"time_column_name\":\"date\",\"grain_column_names\":null,\"drop_column_names\":[\"casual\",\"registered\"],\"max_horizon\":14,\"dropna\":false,\"overwrite_columns\":true,\"transform_dictionary\":{\"min\":\"_automl_target_col\",\"max\":\"_automl_target_col\",\"mean\":\"_automl_target_col\"},\"window_size\":null,\"country_or_region\":\"US\",\"lags\":{\"_automl_target_col\":[\"auto\"]},\"feature_lags\":null,\"seasonality\":-1,\"use_stl\":null,\"short_series_handling\":true,\"enable_early_stopping\":true,\"early_stopping_n_iters\":10,\"metrics\":null,\"enable_ensembling\":true,\"enable_stack_ensembling\":true,\"ensemble_iterations\":15,\"enable_tf\":false,\"enable_cache\":true,\"enable_subsampling\":false,\"subsample_seed\":null,\"enable_nimbusml\":false,\"enable_streaming\":false,\"force_streaming\":false,\"track_child_runs\":true,\"label_column_name\":\"cnt\",\"weight_column_name\":null,\"cv_split_column_names\":null,\"cost_mode\":1,\"metric_operation\":\"minimize\",\"preprocess\":true,\"blocked_models\":[\"ExtremeRandomTrees\"],\"scenario\":\"SDK-Compatible\"}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\": \\\\\"{\\\\\\\\\\\\\"blocks\\\\\\\\\\\\\": [{\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"271a9897-df82-453c-a50d-c390d34717a1\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.GetDatastoreFilesBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"datastores\\\\\\\\\\\\\": [{\\\\\\\\\\\\\"datastoreName\\\\\\\\\\\\\": \\\\\\\\\\\\\"workspaceblobstore\\\\\\\\\\\\\", \\\\\\\\\\\\\"path\\\\\\\\\\\\\": \\\\\\\\\\\\\"./bike-no.csv\\\\\\\\\\\\\", \\\\\\\\\\\\\"resourceGroup\\\\\\\\\\\\\": \\\\\\\\\\\\\"synapse-rg\\\\\\\\\\\\\", \\\\\\\\\\\\\"subscription\\\\\\\\\\\\\": \\\\\\\\\\\\\"f8292d2d-2fe0-426b-ac4b-39dcf0166725\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceName\\\\\\\\\\\\\": \\\\\\\\\\\\\"amlworkspace\\\\\\\\\\\\\"}]}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"d17a4293-bc10-4852-b5ce-55f1b25200f0\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ParseDelimitedBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"columnHeadersMode\\\\\\\\\\\\\": 3, \\\\\\\\\\\\\"fileEncoding\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\"handleQuotedLineBreaks\\\\\\\\\\\\\": false, \\\\\\\\\\\\\"preview\\\\\\\\\\\\\": false, \\\\\\\\\\\\\"separator\\\\\\\\\\\\\": \\\\\\\\\\\\\",\\\\\\\\\\\\\", \\\\\\\\\\\\\"skipRows\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\"skipRowsMode\\\\\\\\\\\\\": 0}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"a68d6780-ca39-4a73-9f17-dd211f27f716\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.DropColumnsBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"columns\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 0, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumns\\\\\\\\\\\\\": [\\\\\\\\\\\\\"Path\\\\\\\\\\\\\"]}}}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"df530f15-f159-4648-9c30-fd6207b05590\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.SetColumnTypesBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"columnConversion\\\\\\\\\\\\\": [{\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"instant\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"date\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeArguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"dateTimeFormats\\\\\\\\\\\\\": [\\\\\\\\\\\\\"%m/%d/%Y\\\\\\\\\\\\\"]}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 4}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"season\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"yr\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"mnth\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"weekday\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"weathersit\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"temp\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 3}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"atemp\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 3}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"hum\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 3}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"windspeed\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 3}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"casual\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"registered\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}, {\\\\\\\\\\\\\"column\\\\\\\\\\\\\": {\\\\\\\\\\\\\"type\\\\\\\\\\\\\": 2, \\\\\\\\\\\\\"details\\\\\\\\\\\\\": {\\\\\\\\\\\\\"selectedColumn\\\\\\\\\\\\\": \\\\\\\\\\\\\"cnt\\\\\\\\\\\\\"}}, \\\\\\\\\\\\\"typeProperty\\\\\\\\\\\\\": 2}]}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}, {\\\\\\\\\\\\\"id\\\\\\\\\\\\\": \\\\\\\\\\\\\"34080b14-2389-4a76-83d0-29cd1c37a82b\\\\\\\\\\\\\", \\\\\\\\\\\\\"type\\\\\\\\\\\\\": \\\\\\\\\\\\\"Microsoft.DPrep.ExpressionFilterBlock\\\\\\\\\\\\\", \\\\\\\\\\\\\"arguments\\\\\\\\\\\\\": {\\\\\\\\\\\\\"expression\\\\\\\\\\\\\": {\\\\\\\\\\\\\"r\\\\\\\\\\\\\": [\\\\\\\\\\\\\"And\\\\\\\\\\\\\", [true, {\\\\\\\\\\\\\"r\\\\\\\\\\\\\": [\\\\\\\\\\\\\"Invoke\\\\\\\\\\\\\", [{\\\\\\\\\\\\\"r\\\\\\\\\\\\\": [\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\", \\\\\\\\\\\\\"Value_LE\\\\\\\\\\\\\"]}, [{\\\\\\\\\\\\\"r\\\\\\\\\\\\\": [\\\\\\\\\\\\\"RecordField\\\\\\\\\\\\\", [{\\\\\\\\\\\\\"r\\\\\\\\\\\\\": [\\\\\\\\\\\\\"Identifier\\\\\\\\\\\\\", \\\\\\\\\\\\\"row\\\\\\\\\\\\\"]}, \\\\\\\\\\\\\"date\\\\\\\\\\\\\"]]}, {\\\\\\\\\\\\\"d\\\\\\\\\\\\\": 634819680000000000}]]]}]]}}, \\\\\\\\\\\\\"localData\\\\\\\\\\\\\": {}, \\\\\\\\\\\\\"isEnabled\\\\\\\\\\\\\": true, \\\\\\\\\\\\\"name\\\\\\\\\\\\\": null, \\\\\\\\\\\\\"annotation\\\\\\\\\\\\\": null}], \\\\\\\\\\\\\"inspectors\\\\\\\\\\\\\": [], \\\\\\\\\\\\\"meta\\\\\\\\\\\\\": {\\\\\\\\\\\\\"savedDatasetId\\\\\\\\\\\\\": \\\\\\\\\\\\\"07d6c15e-f760-4217-b750-714bc723b187\\\\\\\\\\\\\", \\\\\\\\\\\\\"datasetType\\\\\\\\\\\\\": \\\\\\\\\\\\\"tabular\\\\\\\\\\\\\", \\\\\\\\\\\\\"subscriptionId\\\\\\\\\\\\\": \\\\\\\\\\\\\"f8292d2d-2fe0-426b-ac4b-39dcf0166725\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceId\\\\\\\\\\\\\": \\\\\\\\\\\\\"d69578ca-aa37-4ba3-92aa-c5aca34bdeb9\\\\\\\\\\\\\", \\\\\\\\\\\\\"workspaceLocation\\\\\\\\\\\\\": \\\\\\\\\\\\\"eastus\\\\\\\\\\\\\", \\\\\\\\\\\\\"TimeSeries_Column:FineGrainTimestamp_\\\\\\\\\\\\\": \\\\\\\\\\\\\"true\\\\\\\\\\\\\"}}\\\\\", \\\\\"activities\\\\\": 0}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'azureml.runsource': 'automl', 'display_task_type': 'forecasting', 'dependencies_versions': '{\"azureml-train\": \"1.6.0\", \"azureml-train-restclients-hyperdrive\": \"1.6.0\", \"azureml-train-core\": \"1.6.0\", \"azureml-train-automl\": \"1.6.0\", \"azureml-train-automl-runtime\": \"1.6.0\", \"azureml-train-automl-client\": \"1.6.0.post1\", \"azureml-telemetry\": \"1.6.0\", \"azureml-sdk\": \"1.6.0\", \"azureml-pipeline\": \"1.6.0\", \"azureml-pipeline-steps\": \"1.6.0\", \"azureml-pipeline-core\": \"1.6.0\", \"azureml-opendatasets\": \"1.6.0\", \"azureml-model-management-sdk\": \"1.0.1b6.post1\", \"azureml-interpret\": \"1.6.0\", \"azureml-explain-model\": \"1.6.0\", \"azureml-defaults\": \"1.6.0\", \"azureml-dataprep\": \"1.6.3\", \"azureml-dataprep-native\": \"14.1.0\", \"azureml-core\": \"1.6.0\", \"azureml-automl-runtime\": \"1.6.0.post1\", \"azureml-automl-core\": \"1.6.0\"}', 'ClientSdkVersion': '1.6.0', 'ClientType': 'SDK', 'environment_cpu_name': 'AzureML-AutoML', 'environment_cpu_version': '29', 'environment_gpu_name': 'AzureML-AutoML-GPU', 'environment_gpu_version': '18', 'root_attribution': 'automl', 'attribution': 'AutoML', 'CancelUri': 'https://eastus.experiments.azureml.net/jasmine/v1.0/subscriptions/f8292d2d-2fe0-426b-ac4b-39dcf0166725/resourceGroups/synapse-rg/providers/Microsoft.MachineLearningServices/workspaces/amlworkspace/experiment/automl-bikeshareforecasting/cancel/AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8', 'Orchestrator': 'AutoML', 'SetupRunId': 'AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8_setup', 'SetupRunContainerId': 'dcid.AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8_setup', 'forecasting_target_lags': '[1]', 'forecasting_target_rolling_window_size': '0', 'forecasting_max_horizon': '14', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": false, \"subsampling\": false, \"dataset_classes\": 586, \"dataset_features\": 126, \"dataset_samples\": 8421, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': 'AutoML_cb2a5e65-f4e0-4491-be5e-8186ab2adbd8_ModelExplain'}, 'inputDatasets': [{'dataset': {'id': '07d6c15e-f760-4217-b750-714bc723b187'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'training_data', 'mechanism': 'Direct'}}], 'logFiles': {}}"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "remote_run.wait_for_completion()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 32,
          "data": {
            "text/plain": "[('timeseriestransformer', TimeSeriesTransformer(featurization_config=None, logger=None,\n           pipeline_type=<TimeSeriesPipelineType.FULL: 1>)), ('stackensembleregressor', StackEnsembleRegressor(base_learners=[('14', Pipeline(memory=None,\n     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=[25, 75], with_centering=False,\n       with_scaling=False)), ('decisiontreeregressor', DecisionTreeRegressor(criterion='friedman_mse', max_depth=None,\n           max_features=None, max_lea...    min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n           splitter='best'))]))],\n            meta_learner=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n      max_iter=1000, normalize=False, positive=False, precompute=False,\n      random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n            training_cv_folds=5))]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "best_run, fitted_model = remote_run.get_output()\n",
        "fitted_model.steps"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{\n  \"name\": \"workspaceblobstore\",\n  \"container_name\": \"azureml-blobstore-d69578ca-aa37-4ba3-92aa-c5aca34bdeb9\",\n  \"account_name\": \"amlworkspace3032050954\",\n  \"protocol\": \"https\",\n  \"endpoint\": \"core.windows.net\"\n}"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "datastore = ws.get_default_datastore()\n",
        "print(datastore)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 33,
          "data": {
            "text/plain": "['atemp', 'atemp_WASNULL', 'horizon_origin', 'hum', 'hum_WASNULL', 'instant', 'instant_WASNULL', 'mnth', 'mnth_WASNULL', 'season', 'season_WASNULL', 'temp', 'temp_WASNULL', 'weathersit', 'weathersit_WASNULL', 'weekday', 'weekday_WASNULL', 'windspeed', 'windspeed_WASNULL', 'yr', 'yr_WASNULL', '_automl_target_col_lag1D', 'year', 'year_iso', 'half', 'quarter', 'month', 'day', 'wday', 'qday', 'week', '_IsPaidTimeOff', '_Holiday_1 day after Christmas Day', '_Holiday_1 day after Columbus Day', '_Holiday_1 day after Independence Day', '_Holiday_1 day after Labor Day', '_Holiday_1 day after Martin Luther King, Jr. Day', '_Holiday_1 day after Memorial Day', \"_Holiday_1 day after New Year's Day\", '_Holiday_1 day after Thanksgiving', '_Holiday_1 day after Veterans Day', \"_Holiday_1 day after Washington's Birthday\", '_Holiday_1 day before Christmas Day', '_Holiday_1 day before Columbus Day', '_Holiday_1 day before Independence Day', '_Holiday_1 day before Labor Day', '_Holiday_1 day before Martin Luther King, Jr. Day', '_Holiday_1 day before Memorial Day', '_Holiday_1 day before Thanksgiving', '_Holiday_1 day before Veterans Day', \"_Holiday_1 day before Washington's Birthday\", '_Holiday_10 days after Thanksgiving', '_Holiday_10 days before Christmas Day', '_Holiday_2 days after Christmas Day', '_Holiday_2 days after Columbus Day', '_Holiday_2 days after Independence Day', '_Holiday_2 days after Labor Day', '_Holiday_2 days after Martin Luther King, Jr. Day', '_Holiday_2 days after Memorial Day', \"_Holiday_2 days after New Year's Day\", '_Holiday_2 days after Thanksgiving', '_Holiday_2 days after Veterans Day', \"_Holiday_2 days after Washington's Birthday\", '_Holiday_2 days before Christmas Day', '_Holiday_2 days before Columbus Day', '_Holiday_2 days before Independence Day', '_Holiday_2 days before Labor Day', '_Holiday_2 days before Martin Luther King, Jr. Day', '_Holiday_2 days before Memorial Day', '_Holiday_2 days before Thanksgiving', '_Holiday_2 days before Veterans Day', \"_Holiday_2 days before Washington's Birthday\", '_Holiday_3 days after Christmas Day', '_Holiday_3 days after Columbus Day', '_Holiday_3 days after Independence Day', \"_Holiday_3 days after New Year's Day\", '_Holiday_3 days after Thanksgiving', '_Holiday_3 days after Veterans Day', '_Holiday_3 days before Christmas Day', '_Holiday_3 days before Columbus Day', '_Holiday_3 days before Independence Day', '_Holiday_3 days before Thanksgiving', '_Holiday_3 days before Veterans Day', '_Holiday_4 days after Christmas Day', '_Holiday_4 days after Columbus Day', '_Holiday_4 days after Independence Day', \"_Holiday_4 days after New Year's Day\", '_Holiday_4 days after Thanksgiving', '_Holiday_4 days after Veterans Day', '_Holiday_4 days before Christmas Day', '_Holiday_4 days before Columbus Day', '_Holiday_4 days before Independence Day', '_Holiday_4 days before Thanksgiving', '_Holiday_4 days before Veterans Day', '_Holiday_5 days after Christmas Day', '_Holiday_5 days after Columbus Day', '_Holiday_5 days after Independence Day', \"_Holiday_5 days after New Year's Day\", '_Holiday_5 days after Thanksgiving', '_Holiday_5 days after Veterans Day', '_Holiday_5 days before Christmas Day', '_Holiday_5 days before Columbus Day', '_Holiday_5 days before Independence Day', '_Holiday_5 days before Thanksgiving', '_Holiday_5 days before Veterans Day', '_Holiday_6 days after Christmas Day', '_Holiday_6 days after Thanksgiving', '_Holiday_6 days before Christmas Day', '_Holiday_6 days before Thanksgiving', '_Holiday_7 days after Thanksgiving', '_Holiday_7 days before Christmas Day', '_Holiday_7 days before Thanksgiving', '_Holiday_8 days after Thanksgiving', '_Holiday_8 days before Christmas Day', '_Holiday_9 days after Thanksgiving', '_Holiday_9 days before Christmas Day', '_Holiday_Christmas Day', '_Holiday_Columbus Day', '_Holiday_Independence Day', '_Holiday_Labor Day', '_Holiday_Martin Luther King, Jr. Day', '_Holiday_Memorial Day', \"_Holiday_New Year's Day\", '_Holiday_Thanksgiving', '_Holiday_Veterans Day', \"_Holiday_Washington's Birthday\"]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "fitted_model.named_steps['timeseriestransformer'].get_engineered_feature_names()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "Dropped      ...       TypeDetected\n0   No          ...       Numeric     \n1   No          ...       DateTime    \n2   No          ...       Numeric     \n3   No          ...       Numeric     \n4   No          ...       Numeric     \n5   No          ...       Numeric     \n6   No          ...       Numeric     \n7   No          ...       Numeric     \n8   No          ...       Numeric     \n9   No          ...       Numeric     \n10  No          ...       Numeric     \n11  No          ...       Numeric     \n\n[12 rows x 5 columns]"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "# Get the featurization summary as a list of JSON\n",
        "featurization_summary = fitted_model.named_steps['timeseriestransformer'].get_featurization_summary()\n",
        "# View the featurization summary as a pandas dataframe\n",
        "pd.DataFrame.from_records(featurization_summary)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "outputs": [],
      "metadata": {},
      "source": [
        "test_experiment = Experiment(ws, experiment_name + \"_test\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 36,
          "data": null,
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'forecasting_script.py'",
          "traceback": [
            "FileNotFoundError : [Errno 2] No such file or directory: 'forecasting_script.py'",
            "Traceback (most recent call last):\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/shutil.py\", line 241, in copy\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\n",
            "  File \"/home/trusted-service-user/cluster-env/env/lib/python3.6/shutil.py\", line 120, in copyfile\n    with open(src, 'rb') as fsrc:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'forecasting_script.py'\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "script_folder = os.path.join(os.getcwd(), 'forecast')\n",
        "print(script_folder)\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "shutil.copy('forecasting_script.py', script_folder)\n",
        "shutil.copy('forecasting_helper.py', script_folder)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 50,
          "data": null,
          "ename": "AttributeError",
          "evalue": "'_OfflineRun' object has no attribute 'input_datasets'",
          "traceback": [
            "AttributeError : '_OfflineRun' object has no attribute 'input_datasets'",
            "Traceback (most recent call last):\n",
            "AttributeError: '_OfflineRun' object has no attribute 'input_datasets'\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "import argparse\n",
        "import azureml.train.automl\n",
        "#from azureml.automl.runtime.shared import forecasting_models\n",
        "from azureml.core import Run\n",
        "from sklearn.externals import joblib\n",
        "#import forecasting_helper\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--max_horizon', type=int, dest='max_horizon',\n",
        "    default=10, help='Max Horizon for forecasting')\n",
        "parser.add_argument(\n",
        "    '--target_column_name', type=str, dest='target_column_name',\n",
        "    help='Target Column Name')\n",
        "parser.add_argument(\n",
        "    '--time_column_name', type=str, dest='time_column_name',\n",
        "    help='Time Column Name')\n",
        "parser.add_argument(\n",
        "    '--frequency', type=str, dest='freq',\n",
        "    help='Frequency of prediction')\n",
        "\n",
        "args = parser.parse_args()\n",
        "max_horizon = args.max_horizon\n",
        "target_column_name = args.target_column_name\n",
        "time_column_name = args.time_column_name\n",
        "freq = args.freq\n",
        "\n",
        "run = Run.get_context()\n",
        "# get input dataset by name\n",
        "test_dataset = run.input_datasets['test_data']\n",
        "\n",
        "grain_column_names = []\n",
        "\n",
        "df = test_dataset.to_pandas_dataframe().reset_index(drop=True)\n",
        "\n",
        "X_test_df = test_dataset.drop_columns(columns=[target_column_name]).to_pandas_dataframe().reset_index(drop=True)\n",
        "y_test_df = test_dataset.with_timestamp_columns(None).keep_columns(columns=[target_column_name]).to_pandas_dataframe()\n",
        "\n",
        "fitted_model = joblib.load('model.pkl')\n",
        "\n",
        "X_test=X_test_df;\t\t\t\t\n",
        "y_test=y_test_df.values.T[0]\n",
        "freq='D'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\t\t\t\t\t\n",
        "\"\"\"\n",
        "    Produce forecasts on a rolling origin over the given test set.\n",
        "    Each iteration makes a forecast for the next 'max_horizon' periods\n",
        "    with respect to the current origin, then advances the origin by the\n",
        "    horizon time duration. The prediction context for each forecast is set so\n",
        "    that the forecaster uses the actual target values prior to the current\n",
        "    origin time for constructing lag features.\n",
        "    This function returns a concatenated DataFrame of rolling forecasts.\n",
        "\"\"\"\n",
        "df_list = []\n",
        "origin_time = X_test[time_column_name].min()\n",
        "while origin_time <= X_test[time_column_name].max():\n",
        "        # Set the horizon time - end date of the forecast\n",
        "        horizon_time = origin_time + max_horizon * to_offset(freq)\n",
        "\n",
        "        # Extract test data from an expanding window up-to the horizon\n",
        "        expand_wind = (X_test[time_column_name] < horizon_time)\n",
        "        X_test_expand = X_test[expand_wind]\n",
        "        y_query_expand = np.zeros(len(X_test_expand)).astype(np.float)\n",
        "        y_query_expand.fill(np.NaN)\n",
        "\n",
        "        if origin_time != X_test[time_column_name].min():\n",
        "            # Set the context by including actuals up-to the origin time\n",
        "            test_context_expand_wind = (X_test[time_column_name] < origin_time)\n",
        "            context_expand_wind = (\n",
        "                X_test_expand[time_column_name] < origin_time)\n",
        "            y_query_expand[context_expand_wind] = y_test[\n",
        "                test_context_expand_wind]\n",
        "\n",
        "        # Make a forecast out to the maximum horizon\n",
        "        y_fcst, X_trans = fitted_model.forecast(X_test_expand, y_query_expand)\n",
        "\n",
        "        # Align forecast with test set for dates within the\n",
        "        # current rolling window\n",
        "        trans_tindex = X_trans.index.get_level_values(time_column_name)\n",
        "        trans_roll_wind = (trans_tindex >= origin_time) & (\n",
        "            trans_tindex < horizon_time)\n",
        "        test_roll_wind = expand_wind & (\n",
        "            X_test[time_column_name] >= origin_time)\n",
        "        df_list.append(align_outputs(y_fcst[trans_roll_wind],\n",
        "                                     X_trans[trans_roll_wind],\n",
        "                                     X_test[test_roll_wind],\n",
        "                                     y_test[test_roll_wind],\n",
        "                                     target_column_name))\n",
        "\n",
        "        # Advance the origin time\n",
        "        origin_time = horizon_time\n",
        "\n",
        "#   return pd.concat(df_list, ignore_index=True)\n",
        "\t\n",
        "df_all =  pd.concat(df_list, ignore_index=True)\n",
        "\t\n",
        "\t\n",
        "\n",
        "file_name = 'outputs/predictions.csv'\n",
        "export_csv = df_all.to_csv(file_name, header=True)\n",
        "\n",
        "# Upload the predictions into artifacts\n",
        "#run.upload_file(name=file_name, path_or_stream=file_name)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 43,
          "data": null,
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'forecasting_helper'",
          "traceback": [
            "ModuleNotFoundError : No module named 'forecasting_helper'",
            "Traceback (most recent call last):\n",
            "ModuleNotFoundError: No module named 'forecasting_helper'\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "import argparse\n",
        "import azureml.train.automl\n",
        "from azureml.automl.runtime.shared import forecasting_models\n",
        "from azureml.core import Run\n",
        "from sklearn.externals import joblib\n",
        "import forecasting_helper\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\n",
        "    '--max_horizon', type=int, dest='max_horizon',\n",
        "    default=10, help='Max Horizon for forecasting')\n",
        "parser.add_argument(\n",
        "    '--target_column_name', type=str, dest='target_column_name',\n",
        "    help='Target Column Name')\n",
        "parser.add_argument(\n",
        "    '--time_column_name', type=str, dest='time_column_name',\n",
        "    help='Time Column Name')\n",
        "parser.add_argument(\n",
        "    '--frequency', type=str, dest='freq',\n",
        "    help='Frequency of prediction')\n",
        "\n",
        "args = parser.parse_args()\n",
        "max_horizon = args.max_horizon\n",
        "target_column_name = args.target_column_name\n",
        "time_column_name = args.time_column_name\n",
        "freq = args.freq\n",
        "\n",
        "run = Run.get_context()\n",
        "# get input dataset by name\n",
        "test_dataset = run.input_datasets['test_data']\n",
        "\n",
        "grain_column_names = []\n",
        "\n",
        "df = test_dataset.to_pandas_dataframe().reset_index(drop=True)\n",
        "\n",
        "X_test_df = test_dataset.drop_columns(columns=[target_column_name]).to_pandas_dataframe().reset_index(drop=True)\n",
        "y_test_df = test_dataset.with_timestamp_columns(None).keep_columns(columns=[target_column_name]).to_pandas_dataframe()\n",
        "\n",
        "fitted_model = joblib.load('model.pkl')\n",
        "\n",
        "df_all = forecasting_helper.do_rolling_forecast(\n",
        "    fitted_model,\n",
        "    X_test_df,\n",
        "    y_test_df.values.T[0],\n",
        "    target_column_name,\n",
        "    time_column_name,\n",
        "    max_horizon,\n",
        "    freq)\n",
        "\n",
        "file_name = 'outputs/predictions.csv'\n",
        "export_csv = df_all.to_csv(file_name, header=True)\n",
        "\n",
        "# Upload the predictions into artifacts\n",
        "run.upload_file(name=file_name, path_or_stream=file_name)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 38,
          "data": null,
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'run_forecast'",
          "traceback": [
            "ModuleNotFoundError : No module named 'run_forecast'",
            "Traceback (most recent call last):\n",
            "ModuleNotFoundError: No module named 'run_forecast'\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "from run_forecast import run_rolling_forecast\n",
        "\n",
        "remote_run = run_rolling_forecast(test_experiment, compute_target, best_run, test, max_horizon,\n",
        "                 target_column_name, time_column_name)\n",
        "remote_run"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "remote_run.wait_for_completion(show_output=False)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "remote_run.download_file('output/predictions.csv', 'predictions.csv')\n",
        "df_all = pd.read_csv('predictions.csv')"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "status": "error",
          "execution_count": 39,
          "data": null,
          "ename": "NameError",
          "evalue": "name 'df_all' is not defined",
          "traceback": [
            "NameError : name 'df_all' is not defined",
            "Traceback (most recent call last):\n",
            "NameError: name 'df_all' is not defined\n"
          ]
        }
      ],
      "metadata": {},
      "source": [
        "\n",
        "from azureml.automl.core.shared import constants\n",
        "from azureml.automl.runtime.shared.score import scoring\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# use automl metrics module\n",
        "scores = scoring.score_regression(\n",
        "    y_test=df_all[target_column_name],\n",
        "    y_pred=df_all['predicted'],\n",
        "    metrics=list(constants.Metric.SCALAR_REGRESSION_SET))\n",
        "\n",
        "print(\"[Test data scores]\\n\")\n",
        "for key, value in scores.items():    \n",
        "    print('{}:   {:.3f}'.format(key, value))\n",
        "    \n",
        "# Plot outputs\n",
        "%matplotlib inline\n",
        "test_pred = plt.scatter(df_all[target_column_name], df_all['predicted'], color='b')\n",
        "test_test = plt.scatter(df_all[target_column_name], df_all[target_column_name], color='g')\n",
        "plt.legend((test_pred, test_test), ('prediction', 'truth'), loc='upper left', fontsize=8)\n",
        "plt.show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "\n",
        "from metrics_helper import MAPE, APE\n",
        "df_all.groupby('horizon_origin').apply(\n",
        "    lambda df: pd.Series({'MAPE': MAPE(df[target_column_name], df['predicted']),\n",
        "                          'RMSE': np.sqrt(mean_squared_error(df[target_column_name], df['predicted'])),\n",
        "                          'MAE': mean_absolute_error(df[target_column_name], df['predicted'])}))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "\n",
        "df_all_APE = df_all.assign(APE=APE(df_all[target_column_name], df_all['predicted']))\n",
        "APEs = [df_all_APE[df_all['horizon_origin'] == h].APE.values for h in range(1, max_horizon + 1)]\n",
        "\n",
        "%matplotlib inline\n",
        "plt.boxplot(APEs)\n",
        "plt.yscale('log')\n",
        "plt.xlabel('horizon')\n",
        "plt.ylabel('APE (%)')\n",
        "plt.title('Absolute Percentage Errors by Forecast Horizon')\n",
        "\n",
        "plt.show()"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [],
      "attachments": {}
    }
  ]
}